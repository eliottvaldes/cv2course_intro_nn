{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSyHYynK2DCy"
      },
      "source": [
        "# Perceptrón Simple\n",
        "(Ejercicio, 3 puntos posibles)\n",
        "\n",
        "En este notebook programaremos un perceptron simple utilizando numpy. El objetivo es que comprendamos el funcionamiento del perceptrón y que practiquemos la programación en Python. En la siguiente figura se encuentra una representación del perceptrón.\n",
        "\n",
        "<img src=\"https://github.com/eliottvaldes/cv2course_intro_nn/blob/master/files/simple_nn_notebook.png?raw=1\">\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/irvingvasquez/cv2course_intro_nn/blob/master/02_red_neuronal_simple.ipynb)\n",
        "\n",
        "@juan1rving\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hvHroa6O2DC2"
      },
      "outputs": [],
      "source": [
        "# Cargamos paquetes\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIYFxxrJ2DC4"
      },
      "source": [
        "### Calcular producto punto\n",
        "\n",
        "El primer paso es calcular el logit, *h*, a partir del producto punto. La fórmula explícita es la siguiente:\n",
        "\n",
        "$$ h = W X +b $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0O6okrCe2DC4"
      },
      "outputs": [],
      "source": [
        "# TODO: (1 punto) Implementar la función h sin utilizar funciones predefinidas de numpy como numpy.matmul()\n",
        "\n",
        "def combinacion_lineal(W, X, b):\n",
        "    suma = None\n",
        "    return suma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpggCFY22DC5"
      },
      "source": [
        "### Función de activación\n",
        "\n",
        "Para este ejemplo utilizaremos la función escalón como función de activación.\n",
        "\n",
        "$$ \tf(h) = \\begin{cases}\n",
        "\t\t0 & \\text{if } h < a \\\\\n",
        "\t\t1 & \\text{if } h \\geq a\n",
        "\\end{cases}  $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "svcGMglJ2DC5"
      },
      "outputs": [],
      "source": [
        "# TODO: (1 punto) Completar el código\n",
        "def escalon(h):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFOnL30a2DC5"
      },
      "source": [
        "## Definir perceptrón\n",
        "\n",
        "Perceptrón como una función"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "g_RteFUd2DC6"
      },
      "outputs": [],
      "source": [
        "# Perceptrón simple\n",
        "def perceptron(W, X, b, activacion):\n",
        "    h = combinacion_lineal(W, X, b)\n",
        "    return activacion(h)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCuu9eML2DC6"
      },
      "source": [
        "## Probar inferencia\n",
        "\n",
        "Ahora definamos unos pesos y veamos el resultado de una pasada frontal (fordward pass)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CJ_nfydF2DC7",
        "outputId": "567be3a5-f7a5-436a-85a5-456223d32837",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Definamos unos pesos y sesgo\n",
        "inputs = np.array([0.7, -0.3])\n",
        "weights = np.array([0.1, 0.8])\n",
        "bias = -0.1\n",
        "\n",
        "# Pasada frontal\n",
        "activacion = escalon #definir la función a usar\n",
        "output = perceptron(weights, inputs, bias, activacion)\n",
        "\n",
        "print('Output:')\n",
        "print(output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZfP5CCly2DC8"
      },
      "outputs": [],
      "source": [
        "# TODO (1 punto): Realizar el pase frontal y encuentra por prueba y error los pesos que concuerdan con la función OR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CvJa96_h2DC8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "nni",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "cbad788490f55b163920bee5e9d5e0cba00db5905dc94f4bdbe0011e55bf465f"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}